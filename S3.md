# AWS S3 Setup Guide for Image Uploads

This guide walks you through setting up AWS S3 for production image uploads while maintaining local file storage for development.

## Table of Contents
1. [Prerequisites](#prerequisites)
2. [AWS S3 Bucket Setup](#aws-s3-bucket-setup)
3. [IAM Permissions Setup](#iam-permissions-setup)
   - [Option A: Elastic Beanstalk with IAM Role (Recommended)](#option-a-elastic-beanstalk-with-iam-role-recommended)
   - [Option B: IAM User with Access Keys](#option-b-iam-user-with-access-keys)
4. [Environment Configuration](#environment-configuration)
5. [Testing](#testing)
6. [Troubleshooting](#troubleshooting)

## Prerequisites

- AWS Account
- AWS CLI (optional, but recommended)
- Node.js application with file upload capability

## AWS S3 Bucket Setup

### Step 1: Create an S3 Bucket

1. Log in to the [AWS Management Console](https://console.aws.amazon.com/)
2. Navigate to **S3** service
3. Click **Create bucket**
4. Configure your bucket:
   - **Bucket name**: Choose a unique name (e.g., `your-app-name-uploads`)
   - **AWS Region**: Choose a region close to your users (e.g., `us-east-1`)
   - **Object Ownership**: Select "ACLs disabled (recommended)"
   - **Block Public Access settings**: Keep all boxes checked for now (we'll configure public access later)
   - **Bucket Versioning**: Optional (recommended for production)
   - **Tags**: Optional (add tags like `Environment: Production`)
   - **Default encryption**: Enable with Amazon S3 managed keys (SSE-S3)
5. Click **Create bucket**

### Step 2: Configure Bucket for Public Read Access

For profile images that need to be publicly accessible:

1. Go to your bucket
2. Click on the **Permissions** tab
3. Scroll to **Block public access (bucket settings)**
4. Click **Edit**
5. Uncheck "Block all public access"
6. Acknowledge the warning and save changes
7. Scroll to **Bucket policy**
8. Click **Edit** and add the following policy (replace `YOUR-BUCKET-NAME`):

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "PublicReadGetObject",
            "Effect": "Allow",
            "Principal": "*",
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::YOUR-BUCKET-NAME/*"
        }
    ]
}
```

9. Click **Save changes**

### Step 3: Configure CORS (Cross-Origin Resource Sharing)

If your application domain is different from S3:

1. In your bucket, go to the **Permissions** tab
2. Scroll to **Cross-origin resource sharing (CORS)**
3. Click **Edit**
4. Add the following CORS configuration:

```json
[
    {
        "AllowedHeaders": ["*"],
        "AllowedMethods": ["GET", "PUT", "POST", "DELETE"],
        "AllowedOrigins": ["*"],
        "ExposeHeaders": ["ETag"]
    }
]
```

5. Click **Save changes**

**Note**: In production, replace `"*"` in AllowedOrigins with your specific domain(s) for better security.

## IAM Permissions Setup

Choose the option that matches your deployment method:

### Option A: Elastic Beanstalk with IAM Role (Recommended)

If you're deploying to AWS Elastic Beanstalk, you should use IAM roles instead of access keys. This is more secure and eliminates the need to manage credentials.

#### Step 1: Verify Your Elastic Beanstalk IAM Role

1. Navigate to **IAM** service in AWS Console
2. Click **Roles** in the left sidebar
3. Find your Elastic Beanstalk instance role (e.g., `LabRole` or `aws-elasticbeanstalk-ec2-role`)
4. Click on the role name to view its details

#### Step 2: Add S3 Permissions to the Role

1. In the role details page, click on the **Permissions** tab
2. Click **Add permissions** → **Create inline policy**
3. Click the **JSON** tab
4. Paste the following policy (replace `YOUR-BUCKET-NAME` with your actual bucket name):

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:PutObject",
                "s3:PutObjectAcl",
                "s3:GetObject",
                "s3:DeleteObject"
            ],
            "Resource": "arn:aws:s3:::YOUR-BUCKET-NAME/*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:ListBucket"
            ],
            "Resource": "arn:aws:s3:::YOUR-BUCKET-NAME"
        }
    ]
}
```

5. Click **Next**
6. Name your policy (e.g., `S3-Upload-Policy`)
7. Click **Create policy**

#### Step 3: Update Environment Variables

For Elastic Beanstalk, you only need to set:
- `AWS_REGION` (e.g., `us-east-1`)
- `AWS_S3_BUCKET_NAME` (your bucket name)
- `NODE_ENV=production`

**You do NOT need** `AWS_ACCESS_KEY_ID` or `AWS_SECRET_ACCESS_KEY` - the IAM role provides these automatically!

### Option B: IAM User with Access Keys

Use this option if you're deploying to a non-AWS platform (Heroku, DigitalOcean, etc.) or need to access S3 from outside AWS.

#### Step 1: Create an IAM User

1. Navigate to **IAM** service in AWS Console
2. Click **Users** in the left sidebar
3. Click **Create user**
4. Enter a username (e.g., `s3-upload-user`)
5. Click **Next**
6. Select **Attach policies directly**
7. For now, click **Next** (we'll create a custom policy)
8. Review and click **Create user**

#### Step 2: Create a Custom Policy

1. In IAM, click **Policies** in the left sidebar
2. Click **Create policy**
3. Click the **JSON** tab
4. Paste the following policy (replace `YOUR-BUCKET-NAME`):

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:PutObject",
                "s3:PutObjectAcl",
                "s3:GetObject",
                "s3:DeleteObject"
            ],
            "Resource": "arn:aws:s3:::YOUR-BUCKET-NAME/*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:ListBucket"
            ],
            "Resource": "arn:aws:s3:::YOUR-BUCKET-NAME"
        }
    ]
}
```

5. Click **Next**
6. Name your policy (e.g., `S3-Upload-Policy`)
7. Add a description (optional)
8. Click **Create policy**

#### Step 3: Attach Policy to User

1. Go back to **Users** in IAM
2. Click on the user you created (`s3-upload-user`)
3. Click **Add permissions** → **Attach policies directly**
4. Search for your policy name (`S3-Upload-Policy`)
5. Check the box next to your policy
6. Click **Add permissions**

#### Step 4: Create Access Keys

1. While viewing your IAM user, click on the **Security credentials** tab
2. Scroll to **Access keys**
3. Click **Create access key**
4. Select **Application running outside AWS**
5. Check the confirmation box
6. Click **Next**
7. Add a description tag (optional)
8. Click **Create access key**
9. **IMPORTANT**: Copy both the **Access key ID** and **Secret access key**
   - You won't be able to see the secret access key again!
   - Store them securely (you'll add them to your `.env` file)

## Environment Configuration

### Development Environment (.env file)

For local development, create a `.env` file with:

```bash
# AWS S3 Configuration (only needed for local testing of S3)
AWS_ACCESS_KEY_ID=your-access-key-id
AWS_SECRET_ACCESS_KEY=your-secret-access-key
AWS_REGION=us-east-1
AWS_S3_BUCKET_NAME=your-bucket-name

# Environment (leave as development for local work)
NODE_ENV=development
```

**Note**: In development mode, files are stored locally in the `images/uploads/` directory by default, so you don't need AWS credentials unless you want to test S3 functionality locally.

### Production Environment

Choose the configuration method based on your hosting platform:

#### For Elastic Beanstalk (Using IAM Role)

1. Go to your Elastic Beanstalk environment in the AWS Console
2. Click **Configuration** in the left sidebar
3. Find the **Software** section and click **Edit**
4. Under **Environment properties**, add:
   - `NODE_ENV` = `production`
   - `AWS_REGION` = your region (e.g., `us-east-1`)
   - `AWS_S3_BUCKET_NAME` = your bucket name

**Do NOT set** `AWS_ACCESS_KEY_ID` or `AWS_SECRET_ACCESS_KEY` - these are provided automatically by the LabRole!

5. Click **Apply**

#### For Other Platforms (Heroku, DigitalOcean, etc.)

Set all environment variables including access keys:

```bash
# Example for Heroku
heroku config:set NODE_ENV=production
heroku config:set AWS_ACCESS_KEY_ID=your-access-key-id
heroku config:set AWS_SECRET_ACCESS_KEY=your-secret-access-key
heroku config:set AWS_REGION=us-east-1
heroku config:set AWS_S3_BUCKET_NAME=your-bucket-name
```

**Important**: Never commit your `.env` file to version control!

## Testing

### Test in Development Mode

1. Ensure `NODE_ENV=development` (or leave it unset)
2. Start your application: `npm start`
3. Upload a profile image
4. Verify the file is saved to `images/uploads/` directory
5. Verify you can view the image in your application

### Test in Production Mode

1. Set `NODE_ENV=production` in `.env`
2. Restart your application
3. Upload a profile image
4. Check your S3 bucket to verify the file was uploaded
5. Verify you can view the image in your application
6. The image URL should be the S3 URL (e.g., `https://your-bucket-name.s3.amazonaws.com/...`)

## Troubleshooting

### Common Issues

#### 1. "Access Denied" Error

**Problem**: Unable to upload files to S3

**Solutions**:
- Verify your IAM user has the correct permissions
- Check that your AWS credentials are correct in `.env`
- Ensure the bucket policy allows uploads
- Verify the bucket name in your `.env` matches the actual bucket

#### 2. "Cannot Read File" or 404 Errors

**Problem**: Uploaded images don't display

**Solutions**:
- Verify the bucket policy allows public read access
- Check CORS configuration
- Ensure the bucket is in the correct region
- Verify the file URL is correct

#### 3. "SignatureDoesNotMatch" Error

**Problem**: AWS signature validation fails

**Solutions**:
- Verify your Secret Access Key is correct
- Ensure there are no extra spaces in your `.env` file
- Check that your system clock is accurate

#### 4. Large Files Failing to Upload

**Problem**: Large images timeout or fail

**Solutions**:
- Increase timeout settings in your application
- Implement multipart uploads for files > 5MB
- Add file size validation before upload

### Debugging Tips

1. **Enable Debug Logging**: Set `AWS_SDK_LOAD_CONFIG=1` to see detailed AWS SDK logs
2. **Check S3 Bucket**: Manually upload a file through AWS Console to verify bucket configuration
3. **Test IAM Permissions**: Use the AWS CLI to test your credentials:
   ```bash
   aws s3 ls s3://your-bucket-name --profile your-profile
   ```
4. **Verify Environment Variables**: Add a debug endpoint to verify env vars are loaded:
   ```javascript
   app.get('/debug/env', (req, res) => {
       res.json({
           nodeEnv: process.env.NODE_ENV,
           hasAwsKey: !!process.env.AWS_ACCESS_KEY_ID,
           hasAwsSecret: !!process.env.AWS_SECRET_ACCESS_KEY,
           region: process.env.AWS_REGION,
           bucket: process.env.AWS_S3_BUCKET_NAME
       });
   });
   ```

## Security Best Practices

1. **Use IAM roles for AWS deployments (RECOMMENDED)**: When deploying to Elastic Beanstalk, EC2, Lambda, or other AWS services, always use IAM roles instead of access keys. This is more secure and eliminates credential management.
2. **Never commit `.env` to version control**: Add `.env` to `.gitignore`
3. **Rotate access keys regularly** (if you must use them): Create new keys and delete old ones every 90 days
4. **Limit bucket policy**: Only allow public read on the specific paths needed (e.g., `uploads/*` folder only)
5. **Enable bucket versioning**: Helps recover from accidental deletions
6. **Enable logging**: Track who is accessing your bucket
7. **Use HTTPS only**: Ensure your application only serves images over HTTPS in production

## Cost Considerations

AWS S3 pricing includes:
- **Storage**: ~$0.023 per GB/month (first 50 TB)
- **Requests**: ~$0.005 per 1,000 PUT requests, ~$0.0004 per 1,000 GET requests
- **Data Transfer**: First 1 GB/month is free, then ~$0.09 per GB

For a typical small application with profile images:
- 1,000 users × 500KB per image = ~500 MB storage = ~$0.01/month
- Image uploads and views typically cost < $1/month

## Next Steps

1. Set up CloudFront CDN for faster global image delivery
2. Implement image resizing/optimization before upload
3. Add image format validation
4. Set up S3 lifecycle policies to archive old images
5. Configure CloudWatch alarms for monitoring uploads

## Additional Resources

- [AWS S3 Documentation](https://docs.aws.amazon.com/s3/)
- [AWS SDK for JavaScript v3](https://docs.aws.amazon.com/sdk-for-javascript/v3/developer-guide/)
- [Multer S3 Documentation](https://www.npmjs.com/package/multer-s3)
- [AWS S3 Best Practices](https://docs.aws.amazon.com/AmazonS3/latest/userguide/best-practices.html)
